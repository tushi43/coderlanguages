<!DOCTYPE HTML>
<HTML>
<head>
	<title>Hadoop</title>
</head>
<body>
	<img src ="images/Bigdata.jpg" height="250" width="400" style="margin:auto; display:block;" ><br>
	<img src="images/hadoop.png" height="120x" width="400px">
	<h1><!--Name-->Hadoop</h1>
	In this world of Big Data, where every day huge amount of data is produced it is necessary to store and process that data efficiently in each organiztion.The Problem of Big Data is to handle four V's that are Volume(Size of data), Variety(different type of data both structured and unstructured), Velocity(speed of processing) and Veracity(Verificatin of data). For this Apache has developed open source framework called Hadoop. Hadoop is becoming popular because today more than 80% of data generated is in unstructured form and data is generating in multi terabytes. So, It is not possible to store that huge amount of data in RDBMS. Hadoop allows distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Hadoop consists of these modules: Hadoop Common, Hadoop Distributed File System (HDFS), YARN, MapReduce.<br>
	HDFS enables distribution of the large data sets over multiple nodes(servers), YARN helps in job scheduling and cluster resource management and the most important module MapReduce(which is algorithm) enables parallel processing over the data sets which increases the processing speed, it divides the data sets in small chunks and does the processing. To understand Hadoop you need to understand how it stores data and how it process data. Hadoop is complex built platform so do use and understand it you need to have prior knowledge of Java Programming language.<br><br>

	<div style="display:block; margin:auto;">
	<iframe width="560" height="265" src="https://www.youtube.com/embed/9s-vSeWej1U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
	</div><br><br>
	<h1>Popular Applicatons:</h1> 
	Hadoop is used along with different tools by different companies.
	example: Amazon Web Services, IBM, Intel, Microsoft and more.<br>
	<br>
	<h1>Hadoop Related projects:</h1> 
	<ol><img src="images/cassandra.png" height="120x" width="200px"><li><h1>Cassandra:</h1>It is a distributed database for managing large amounts of structured data across many commodity servers, while providing highly available service and no single point of failure. This project was started at Facebook and built on Amazon’s Dynamo and Google’s BigTable and Now, developed by Apache.<br> Cassandra is Fault-tolerant because, replication is done at multiple nodes and failed nodes can be replaced in no time. It is highly scalable and elastic. Cassandra consistently outperforms popular NoSQL alternatives in benchmarks and real applications. <br> Cassandra is in use at Constant Contact, Facebook, CERN, Comcast, eBay, GitHub, GoDaddy, Hulu, Instagram, Intuit, Netflix, Reddit, The Weather Channel, and over 1500 more companies that have large, active data sets. <br> 
	Source: <a href="http://cassandra.apache.org/" target="_blank" class="a1">Official website</a><br><br>
	 </li>
	<img src="images/hbase.png" height="100x" width="400px"><li><h1>HBase:</h1>Apache HBase is an open-source, distributed, versioned, non-relational database modeled after Google's Bigtable. HBase is needed when a company need random, realtime read/write access to its Big Data. The goal of developing this project is the hosting of very large tables which has billions of rows X millions of columns and a top clusters of commodity hardware. HBase provides Bigtable-like capabilities on top of Hadoop and HDFS. Some applicationsthat use HBase are Facebook, NetFlix, Adobe, Airbnb.<br> Source: <a href="http://hbase.apache.org/" target="_blank" class="a1">Official website</a><br><br></li>
	<img src="images/hive.jpg" height="100x" width="100px"><li><h1>Hive:</h1></li>
	The Apache Hive data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Initially, It was a sub-project under Hadoop but now is top-level project of Apache. Hive provides standard SQL functionality. Components of Hive include HCatalog and WebHCat.<br>  Source: <a href="http://hive.apache.org/" target="_blank" class="a1">Official website</a> 
	<br><br>
	<h1>Source:</h1>
	<a href="http://hadoop.apache.org/" target="_blank" class="a1">Official website</a><br>

</body>
</html>